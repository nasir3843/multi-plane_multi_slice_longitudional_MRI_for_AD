{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f0132f2-9fe8-400a-aa52-fa8b145753d7",
   "metadata": {},
   "source": [
    "## This code is associated with Experiment 3 described in the manuscript for AD progression detection using 3D-CNN-BiLSTM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eaffecd-7464-4130-9830-53d7299412bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import numpy as np\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.metrics import BinaryAccuracy, Precision, Recall, AUC, SpecificityAtSensitivity\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import tensorflow.keras.backend as K\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from classification_models_3D.kkeras import Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "288802ab-ee85-4a6b-aabf-8c47bca406f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_backbone_model(backbone_name, input_shape):\n",
    "    \"\"\"Get the specified backbone model\"\"\"\n",
    "    backbone_models = {\n",
    "        'resnet50': 'resnet50',\n",
    "        'vgg16': 'vgg16', \n",
    "        'densenet121': 'densenet121',\n",
    "        'inceptionv3': 'inceptionv3',\n",
    "        'efficientnetb7': 'efficientnetb7'}\n",
    "    \n",
    "    if backbone_name not in backbone_models:\n",
    "        raise ValueError(f\"Unsupported backbone: {backbone_name}\")\n",
    "    BackboneModel, preprocess_input = Classifiers.get(backbone_models[backbone_name])\n",
    "    backbone = BackboneModel(input_shape=input_shape, weights=None, include_top=False)\n",
    "    return backbone, preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f4efae1-a1ce-470f-a642-92597121b74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class F1Score(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='f1_score', **kwargs):\n",
    "        super(F1Score, self).__init__(name=name, **kwargs)\n",
    "        self.precision_metric = Precision()\n",
    "        self.recall_metric = Recall()\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        self.precision_metric.update_state(y_true, y_pred, sample_weight)\n",
    "        self.recall_metric.update_state(y_true, y_pred, sample_weight)\n",
    "    def result(self):\n",
    "        precision = self.precision_metric.result()\n",
    "        recall = self.recall_metric.result()\n",
    "        return 2 * ((precision * recall) / (precision + recall + K.epsilon()))\n",
    "    def reset_state(self):\n",
    "        self.precision_metric.reset_state()\n",
    "        self.recall_metric.reset_state()\n",
    "def specificity(y_true, y_pred):\n",
    "    neg_y_true = 1 - y_true\n",
    "    neg_y_pred = 1 - y_pred\n",
    "    fp = K.sum(neg_y_true * y_pred)\n",
    "    tn = K.sum(neg_y_true * neg_y_pred)\n",
    "    specificity = tn / (tn + fp + K.epsilon()) \n",
    "    return specificity\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss', patience=5, restore_best_weights=True, verbose=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f46fc78f-1896-4fb6-ad66-48d651234ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(X_data, timesteps, view):\n",
    "    view_map = { 'axial_coronal': 1, 'axial_coronal_sagittal': 2}\n",
    "    view_option = view_map[view]\n",
    "    timestep_map = {'one': 1, 'two': 2, 'three': 3, 'four': 4}\n",
    "    n_timesteps = timestep_map[timesteps]    \n",
    "    message = ''\n",
    "    data_formate = 0\n",
    "    if view_option == 1: # axial_coronal\n",
    "        axial_coronal_views = X_data[:, 0:128, :, :,  :]        \n",
    "        axial = axial_coronal_views[:, 0:64, :, :,  :]\n",
    "        coronal = axial_coronal_views[:, 64:128, :, :, :]        \n",
    "        if n_timesteps == 1:\n",
    "            axial = axial[:, 0:16, :, :,  :] # axial\n",
    "            coronal = coronal[:, 0:16, :, :, :] # coronal\n",
    "            axial_coronal_all_steps = tf.concat([axial, coronal], axis=1)\n",
    "            message = 'Data for Single time-step for axial_coronal view returned.'\n",
    "            print(message)\n",
    "            data_formate = axial_coronal_all_steps\n",
    "        elif n_timesteps == 2:\n",
    "            axial = axial[:, 0:32, :, :,  :] # axial\n",
    "            coronal = coronal[:, 0:32, :, :, :] # coronal\n",
    "            axial_coronal_all_steps = tf.concat([axial, coronal], axis=1)\n",
    "            message = 'Data for two time-steps for axial_coronal view returned.'\n",
    "            print(message)\n",
    "            data_formate = axial_coronal_all_steps\n",
    "        elif n_timesteps == 3:\n",
    "            axial = axial[:, 0:48, :, :,  :] # axial\n",
    "            coronal = coronal[:, 0:48, :, :, :] # coronal\n",
    "            axial_coronal_all_steps = tf.concat([axial, coronal], axis=1)\n",
    "            message = 'Data for three time-steps for axial_coronal view returned.'\n",
    "            print(message)\n",
    "            data_formate = axial_coronal_all_steps\n",
    "        else:\n",
    "            axial = axial[:, 0:64, :, :,  :] # axial\n",
    "            coronal = coronal[:, 0:64, :, :, :] # coronal\n",
    "            axial_coronal_all_steps = tf.concat([axial, coronal], axis=1)\n",
    "            message = 'Data for four time-steps for axial_coronal view returned.'\n",
    "            print(message)\n",
    "            data_formate = axial_coronal_all_steps\n",
    "    else: # axial_coronal_sagittal view\n",
    "        axial_coronal_views = X_data[:, 0:192, :, :,  :]\n",
    "        axial = axial_coronal_views[:, 0:64, :, :,  :]\n",
    "        coronal = axial_coronal_views[:, 64:128, :, :, :]\n",
    "        sagittal = axial_coronal_views[:, 128:192, :, :, :] \n",
    "        if n_timesteps == 1:\n",
    "            axial = axial[:, 0:16, :, :,  :] # axial\n",
    "            coronal = coronal[:, 0:16, :, :, :] # coronal\n",
    "            sagittal = sagittal[:, 0:16, :, :, :] # sagittal\n",
    "            axial_coronal_all_steps = tf.concat([axial, coronal, sagittal], axis=1)\n",
    "            message = 'Data for Single time-steps for axial_coronal_sagittal view returned.'\n",
    "            print(message)\n",
    "            data_formate = axial_coronal_all_steps\n",
    "        elif n_timesteps == 2:\n",
    "            axial = axial[:, 0:32, :, :,  :] # axial\n",
    "            coronal = coronal[:, 0:32, :, :, :] # coronal\n",
    "            sagittal = sagittal[:, 0:32, :, :, :] # sagittal\n",
    "            axial_coronal_all_steps = tf.concat([axial, coronal, sagittal], axis=1)\n",
    "            message = 'Data for Two time-steps for axial_coronal_sagittal view returned.'\n",
    "            print(message)\n",
    "            data_formate = axial_coronal_all_steps\n",
    "        elif n_timesteps == 3:\n",
    "            axial = axial[:, 0:48, :, :,  :] # axial\n",
    "            coronal = coronal[:, 0:48, :, :, :] # coronal\n",
    "            sagittal = sagittal[:, 0:48, :, :, :] # sagittal\n",
    "            axial_coronal_all_steps = tf.concat([axial, coronal, sagittal], axis=1)\n",
    "            message = 'Data for Three time-steps for axial_coronal_sagittal view returned.'\n",
    "            print(message)\n",
    "            data_formate = axial_coronal_all_steps           \n",
    "        else:\n",
    "            axial = axial[:, 0:64, :, :,  :] # axial\n",
    "            coronal = coronal[:, 0:64, :, :, :] # coronal\n",
    "            sagittal = sagittal[:, 0:64, :, :, :] # sagittal\n",
    "            axial_coronal_all_steps = tf.concat([axial, coronal, sagittal], axis=1)\n",
    "            message = 'Data for Three time-steps for axial_coronal_sagittal view returned.'\n",
    "            print(message)\n",
    "            data_formate = axial_coronal_all_steps          \n",
    "    return data_formate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fe4007a-1987-4cd3-8361-084f7d5ad032",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def build_model(backbone_name, input_shape, num_classes=2):\n",
    "    backbone, preprocess_input = get_backbone_model(backbone_name, input_shape)\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    x = inputs\n",
    "    features = backbone(x)\n",
    "    gap = layers.GlobalAveragePooling3D(name='global_avg_pool')(features)\n",
    "    gap_size = gap.shape[-1]\n",
    "    if gap_size >= 128:\n",
    "        timesteps = 16\n",
    "        features_per_step = gap_size // timesteps\n",
    "        if gap_size % timesteps != 0:\n",
    "            padding_size = timesteps - (gap_size % timesteps)\n",
    "            gap_padded = layers.Lambda(lambda x: tf.pad(x, [[0, 0], [0, padding_size]], 'constant'))(gap)\n",
    "            gap_size = gap_size + padding_size\n",
    "            features_per_step = gap_size // timesteps\n",
    "        else:\n",
    "            gap_padded = gap\n",
    "        x = layers.Reshape((timesteps, features_per_step), name='reshape_for_bilstm')(gap_padded)\n",
    "    else:\n",
    "        timesteps = 8\n",
    "        features_per_step = max(16, gap_size // timesteps)\n",
    "        gap_expanded = layers.Dense(timesteps * features_per_step, activation='relu', name='expand_for_bilstm')(gap)\n",
    "        x = layers.Reshape((timesteps, features_per_step), name='reshape_for_bilstm')(gap_expanded)\n",
    "    x = layers.Bidirectional(\n",
    "        layers.LSTM(128, \n",
    "            return_sequences=True,  \n",
    "            dropout=0.1,\n",
    "            recurrent_dropout=0.1,\n",
    "            recurrent_regularizer=keras.regularizers.l1(0.01),\n",
    "            name='bilstm_1'\n",
    "        ), name='bidirectional_lstm_1')(x)   \n",
    "    x = layers.Bidirectional(\n",
    "        layers.LSTM(64, \n",
    "            return_sequences=False,  \n",
    "            dropout=0.1, recurrent_dropout=0.1,\n",
    "            recurrent_regularizer=keras.regularizers.l1(0.03),\n",
    "            name='bilstm_2' ), name='bidirectional_lstm_2' )(x)    \n",
    "    x = layers.Dense(64, activation='relu', name='dense_final')(x)\n",
    "    x = layers.Dropout(0.2, name='dropout_final')(x)    \n",
    "    if num_classes == 2:\n",
    "        outputs = layers.Dense(1, activation='sigmoid', name='predictions')(x)\n",
    "        loss = BinaryCrossentropy()\n",
    "        metrics = [\n",
    "            BinaryAccuracy(name='accuracy'),   \n",
    "            Recall(name='Sensitivity'),             \n",
    "            AUC(name='auc'),                   \n",
    "            SpecificityAtSensitivity(0.5) ]\n",
    "    else:\n",
    "        outputs = layers.Dense(num_classes, activation='softmax', name='predictions')(x)\n",
    "        loss = 'sparse_categorical_crossentropy'\n",
    "        \n",
    "    model = Model(inputs, outputs, name=f'{backbone_name}_bilstm_classifier')\n",
    "    return model, loss, metrics, preprocess_input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f6a407-3619-49c1-8913-9351bef28fc3",
   "metadata": {},
   "source": [
    "## Backbone network : [resnet50, vgg16, densenet121, inceptionv3, efficientnetb7].¶\n",
    "## View: axial_coronal OR axial_coronal_sagittal\n",
    "## time_steps: one, two, three, four\n",
    "## n_splits N-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74d5422-3d89-4856-b0a4-706a94292149",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "backbone = 'efficientnetb7'\n",
    "view = 'axial_coronal_sagittal' # \n",
    "time_steps = \"four\"\n",
    "lr = 0.00001\n",
    "n_splits = 10\n",
    "epochs = 120 \n",
    "batch_size = 16\n",
    "\n",
    "\n",
    "# Read the dataset\n",
    "cn_patients = np.read('./CN.npy') # CN patients\n",
    "progressed_to_AD = np.read('./pAD.npy') # Progressed to AD patients\n",
    "cn_labels = np.read('./CN_labels.npy')\n",
    "progressed_to_AD_labels = np.read('./pAD_labels.npy')\n",
    "y_labels = concatenated_y_ensor = tf.concat([CN_y, AD_y], axis=0)\n",
    "X_data = concatenated_y_ensor = tf.concat([CN, AD], axis=0)\n",
    "returned_data = load_data(X_data, time_steps, view)\n",
    "\n",
    "X = tf.convert_to_tensor(returned_data)\n",
    "X_numpy = X.numpy() \n",
    "Y = tf.convert_to_tensor(y_labels)\n",
    "Y_numpy = Y.numpy()\n",
    "\n",
    "\n",
    "histories = []\n",
    "test_history = []\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "for fold, (train_val_idx, test_idx) in enumerate(kf.split(X_numpy, Y_numpy), 1):\n",
    "    print(f\"\\nFold {fold}\")\n",
    "    X_train_val, X_test = X_numpy[train_val_idx], X_numpy[test_idx]\n",
    "    y_train_val, y_test = Y_numpy[train_val_idx], Y_numpy[test_idx]\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train_val, y_train_val,\n",
    "        test_size=0.2,  \n",
    "        stratify=y_train_val,  \n",
    "        random_state=fold )\n",
    "    \n",
    "    input_shape = (X_train.shape[1], 110, 110, 1)\n",
    "    print(\"input shape\", input_shape)\n",
    "    model, loss, metrics, preprocess_input = build_model(backbone, input_shape, num_classes=2 )\n",
    "    optimizer = Adam(learning_rate=lr)\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "    history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epochs, batch_size=batch_size,callbacks=[early_stop], verbose=1)\n",
    "    print(\"Starting training...\")\n",
    "    history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epochs, batch_size=batch_size,callbacks=[early_stop], verbose=1)\n",
    "    test_loss, *test_metrics = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(f\"Test results - Loss: {test_loss}, Metrics: {test_metrics}\")\n",
    "    histories.append(history)\n",
    "    test_history.append(test_metrics)\n",
    "    fold += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbaa57e9-87b0-400e-82cf-47fd6c6b8b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, history in enumerate(test_history):\n",
    "    if hasattr(history, \"history\"):  # Valid Keras History object\n",
    "        print(f\"\\nFold {i+1} Training History:\")\n",
    "        for key in history.history:\n",
    "            print(f\"{key}: {history.history[key]}\")\n",
    "    else:\n",
    "        print(f\"\\nFold {i+1} is not a valid History object (type: {type(history)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f35684-37c1-4484-9154-8ffcdb5807a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97474170-0b33-4241-ba10-b94f4c1e0068",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
