{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "febcf932-2442-46d3-b43a-dfdbbd78a624",
   "metadata": {},
   "source": [
    "## The following code refers to Experiment 2 in the manuscript, we explored the potential improvement in the overall performance of AD progression detection by fusing information from multiple MRI planes during the training process.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197f4dfb-8367-4bdd-90e2-c2a9557f3b02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import numpy as np\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.metrics import BinaryAccuracy, Precision, Recall, AUC, SpecificityAtSensitivity\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import tensorflow.keras.backend as K\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from classification_models_3D.kkeras import Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "288802ab-ee85-4a6b-aabf-8c47bca406f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_backbone_model(backbone_name, input_shape):\n",
    "    \"\"\"Get the specified backbone model\"\"\"\n",
    "    backbone_models = {'resnet50': 'resnet50',\n",
    "                       'vgg16': 'vgg16', 'densenet121': 'densenet121',\n",
    "                       'inceptionv3': 'inceptionv3',\n",
    "                       'efficientnetb7': 'efficientnetb7'}\n",
    "    if backbone_name not in backbone_models:\n",
    "        raise ValueError(f\"Unsupported backbone: {backbone_name}\")\n",
    "    BackboneModel, preprocess_input = Classifiers.get(backbone_models[backbone_name])\n",
    "    backbone = BackboneModel(input_shape=input_shape, weights=None, include_top=False)\n",
    "    return backbone, preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f4efae1-a1ce-470f-a642-92597121b74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class F1Score(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='f1_score', **kwargs):\n",
    "        super(F1Score, self).__init__(name=name, **kwargs)\n",
    "        self.precision_metric = Precision()\n",
    "        self.recall_metric = Recall()\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        self.precision_metric.update_state(y_true, y_pred, sample_weight)\n",
    "        self.recall_metric.update_state(y_true, y_pred, sample_weight)\n",
    "    def result(self):\n",
    "        precision = self.precision_metric.result()\n",
    "        recall = self.recall_metric.result()\n",
    "        return 2 * ((precision * recall) / (precision + recall + K.epsilon()))\n",
    "    def reset_state(self):\n",
    "        self.precision_metric.reset_state()\n",
    "        self.recall_metric.reset_state()\n",
    "def specificity(y_true, y_pred):\n",
    "    neg_y_true = 1 - y_true\n",
    "    neg_y_pred = 1 - y_pred\n",
    "    fp = K.sum(neg_y_true * y_pred)\n",
    "    tn = K.sum(neg_y_true * neg_y_pred)\n",
    "    specificity = tn / (tn + fp + K.epsilon()) \n",
    "    return specificity\n",
    "early_stop = EarlyStopping( monitor='val_loss', patience=5, restore_best_weights=True, verbose=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f46fc78f-1896-4fb6-ad66-48d651234ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_data(data_path, view, timesteps):\n",
    "def load_data(X_data, timesteps, view):\n",
    "    view_map = { 'axial_coronal': 1, 'axial_coronal_sagittal': 2}\n",
    "    view_option = view_map[view]\n",
    "    timestep_map = {'one': 1, 'two': 2, 'three': 3, 'four': 4}\n",
    "    n_timesteps = timestep_map[timesteps]\n",
    "    message = ''\n",
    "    data_formate = 0\n",
    "    if view_option == 1: # axial_coronal\n",
    "        axial_coronal_views = X_data[:, 0:128, :, :,  :]          \n",
    "        axial = axial_coronal_views[:, 0:64, :, :,  :]\n",
    "        coronal = axial_coronal_views[:, 64:128, :, :, :]        \n",
    "        if n_timesteps == 1:\n",
    "            axial = axial[:, 0:16, :, :,  :] # axial\n",
    "            coronal = coronal[:, 0:16, :, :, :] # coronal\n",
    "            axial_coronal_all_steps = tf.concat([axial, coronal], axis=1)\n",
    "            message = 'Data for Single time-step for axial_coronal view returned.'\n",
    "            print(message)\n",
    "            data_formate = axial_coronal_all_steps\n",
    "            \n",
    "        elif n_timesteps == 2:\n",
    "            axial = axial[:, 0:32, :, :,  :] # axial\n",
    "            coronal = coronal[:, 0:32, :, :, :] # coronal\n",
    "            axial_coronal_all_steps = tf.concat([axial, coronal], axis=1)\n",
    "            message = 'Data for two time-steps for axial_coronal view returned.'\n",
    "            print(message)\n",
    "            data_formate = axial_coronal_all_steps\n",
    "        elif n_timesteps == 3:\n",
    "            axial = axial[:, 0:48, :, :,  :] # axial\n",
    "            coronal = coronal[:, 0:48, :, :, :] # coronal\n",
    "            axial_coronal_all_steps = tf.concat([axial, coronal], axis=1)\n",
    "            message = 'Data for three time-steps for axial_coronal view returned.'\n",
    "            print(message)\n",
    "            data_formate = axial_coronal_all_steps\n",
    "        else:\n",
    "            axial = axial[:, 0:64, :, :,  :] # axial\n",
    "            coronal = coronal[:, 0:64, :, :, :] # coronal\n",
    "            axial_coronal_all_steps = tf.concat([axial, coronal], axis=1)\n",
    "            message = 'Data for four time-steps for axial_coronal view returned.'\n",
    "            print(message)\n",
    "            data_formate = axial_coronal_all_steps   \n",
    "    else: # axial_coronal_sagittal view\n",
    "        axial_coronal_views = X_data[:, 0:192, :, :,  :]\n",
    "        axial = axial_coronal_views[:, 0:64, :, :,  :]\n",
    "        coronal = axial_coronal_views[:, 64:128, :, :, :]\n",
    "        sagittal = axial_coronal_views[:, 128:192, :, :, :] \n",
    "        if n_timesteps == 1:\n",
    "            axial = axial[:, 0:16, :, :,  :] # axial\n",
    "            coronal = coronal[:, 0:16, :, :, :] # coronal\n",
    "            sagittal = sagittal[:, 0:16, :, :, :] # sagittal\n",
    "            axial_coronal_all_steps = tf.concat([axial, coronal, sagittal], axis=1)\n",
    "            message = 'Data for Single time-steps for axial_coronal_sagittal view returned.'\n",
    "            print(message)\n",
    "            data_formate = axial_coronal_all_steps\n",
    "        elif n_timesteps == 2:\n",
    "            axial = axial[:, 0:32, :, :,  :] # axial\n",
    "            coronal = coronal[:, 0:32, :, :, :] # coronal\n",
    "            sagittal = sagittal[:, 0:32, :, :, :] # sagittal\n",
    "            axial_coronal_all_steps = tf.concat([axial, coronal, sagittal], axis=1)\n",
    "            message = 'Data for Two time-steps for axial_coronal_sagittal view returned.'\n",
    "            print(message)\n",
    "            data_formate = axial_coronal_all_steps  \n",
    "        elif n_timesteps == 3:\n",
    "            axial = axial[:, 0:48, :, :,  :] # axial\n",
    "            coronal = coronal[:, 0:48, :, :, :] # coronal\n",
    "            sagittal = sagittal[:, 0:48, :, :, :] # sagittal\n",
    "            axial_coronal_all_steps = tf.concat([axial, coronal, sagittal], axis=1)\n",
    "            message = 'Data for Three time-steps for axial_coronal_sagittal view returned.'\n",
    "            print(message)\n",
    "            data_formate = axial_coronal_all_steps           \n",
    "        else:\n",
    "            axial = axial[:, 0:64, :, :,  :] # axial\n",
    "            coronal = coronal[:, 0:64, :, :, :] # coronal\n",
    "            sagittal = sagittal[:, 0:64, :, :, :] # sagittal\n",
    "            axial_coronal_all_steps = tf.concat([axial, coronal, sagittal], axis=1)\n",
    "            message = 'Data for Three time-steps for axial_coronal_sagittal view returned.'\n",
    "            print(message)\n",
    "            data_formate = axial_coronal_all_steps           \n",
    "    return data_formate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fe4007a-1987-4cd3-8361-084f7d5ad032",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def build_model(backbone_name, input_shape, num_classes=2):\n",
    "    backbone, preprocess_input = get_backbone_model(backbone_name, input_shape)\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    x = inputs\n",
    "    features = backbone(x)\n",
    "    gap = layers.GlobalAveragePooling3D(name='global_avg_pool')(features)\n",
    "    gap_size = gap.shape[-1]\n",
    "    if gap_size > 1024:\n",
    "        x = layers.Dense(512, activation='relu', name='dense_reduce')(gap)\n",
    "        x = layers.Dropout(0.3, name='dropout_dense')(x)\n",
    "    elif gap_size < 128:\n",
    "        x = layers.Dense(256, activation='relu', name='dense_expand')(gap)\n",
    "        x = layers.Dropout(0.3, name='dropout_dense')(x) \n",
    "    else:\n",
    "        x = layers.Dropout(0.5, name='dropout')(gap) \n",
    "    if num_classes == 2:\n",
    "        outputs = layers.Dense(1, activation='sigmoid', name='predictions')(x)\n",
    "        loss = BinaryCrossentropy()\n",
    "        metrics = [\n",
    "            BinaryAccuracy(name='accuracy'),     \n",
    "            Recall(name='Sensitivity'),              \n",
    "            AUC(name='auc'),                    \n",
    "            SpecificityAtSensitivity(0.5) ]\n",
    "    else:\n",
    "        outputs = layers.Dense(num_classes, activation='softmax', name='predictions')(x)\n",
    "        loss = 'sparse_categorical_crossentropy'\n",
    "        metrics = ['accuracy']\n",
    "    model = Model(inputs, outputs, name=f'{backbone_name}_classifier')\n",
    "    return model, loss, metrics, preprocess_input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c4854f-ec3f-4c30-ba91-f37620e2232e",
   "metadata": {},
   "source": [
    "## Backbone network can be one of the five predefined 3D CNN models: [resnet50, vgg16, densenet121, inceptionv3, efficientnetb7].¶\n",
    "## View: can be one of the following two options: [axial_coronal, axial_coronal_sagittal].\n",
    "## time_steps:  represent the number of longitudinal time steps the 3D model is trained on. The available options are: [one, two, three, four].\n",
    "## n_splits represents the cross-validation setup for N folds. In this study, we report results for 10-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e1e9c7-5fef-463f-8099-08e8be16bf22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "backbone = 'inceptionv3'\n",
    "view = 'axial_coronal_sagittal'    # axial_coronal, axial_coronal_sagittal\n",
    "time_steps = \"three\"\n",
    "lr = 0.00001\n",
    "n_splits = 10\n",
    "epochs = 120\n",
    "batch_size = 16\n",
    "\n",
    "\n",
    "# Read the dataset\n",
    "cn_patients = np.read('./CN.npy') # CN patients\n",
    "progressed_to_AD = np.read('./pAD.npy') # Progressed to AD patients\n",
    "cn_labels = np.read('./CN_labels.npy')\n",
    "progressed_to_AD_labels = np.read('./pAD_labels.npy')\n",
    "y_labels = concatenated_y_ensor = tf.concat([CN_y, AD_y], axis=0)\n",
    "X_data = concatenated_y_ensor = tf.concat([CN, AD], axis=0)\n",
    "\n",
    "returned_data = load_data(X_data, time_steps, view)\n",
    "X = tf.convert_to_tensor(returned_data)\n",
    "X_numpy = X.numpy() \n",
    "Y = tf.convert_to_tensor(y_labels)\n",
    "Y_numpy = Y.numpy()\n",
    "\n",
    "histories = []\n",
    "test_history = []\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "for fold, (train_val_idx, test_idx) in enumerate(kf.split(X_numpy, Y_numpy), 1):\n",
    "    print(f\"\\nFold {fold}\")\n",
    "    X_train_val, X_test = X_numpy[train_val_idx], X_numpy[test_idx]\n",
    "    y_train_val, y_test = Y_numpy[train_val_idx], Y_numpy[test_idx]\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train_val, y_train_val,\n",
    "        test_size=0.2,  \n",
    "        stratify=y_train_val,  \n",
    "        random_state=fold  )\n",
    "    input_shape = (X_train.shape[1], 110, 110, 1)\n",
    "    print(\"input shape\", input_shape)\n",
    "\n",
    "    model, loss, metrics, preprocess_input = build_model(backbone, input_shape, num_classes=2 )\n",
    "    optimizer = Adam(learning_rate=lr)\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "    history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epochs, batch_size=batch_size,callbacks=[early_stop], verbose=1)\n",
    "    print(\"Starting training...\")\n",
    "    history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epochs, batch_size=batch_size,callbacks=[early_stop], verbose=1)\n",
    "    test_loss, *test_metrics = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(f\"Test results - Loss: {test_loss}, Metrics: {test_metrics}\")\n",
    "    histories.append(history)\n",
    "    test_history.append(test_metrics)\n",
    "    fold += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834061a4-973c-4006-bee3-725745e2115c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to NumPy array\n",
    "history_array = np.array(test_history)\n",
    "# Compute mean for each (metric)\n",
    "avg_metrics = np.mean(history_array, axis=0)\n",
    "# Print with labels\n",
    "metric_names = ['mean-Accuracy', 'mean-Sensitivity', 'mean-Specificity', 'mean-AUC']\n",
    "for name, value in zip(metric_names, avg_metrics):\n",
    "    print(f\"{name}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e675d055-d0b7-47b6-b5d8-462496e28b4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c445e7f-3740-40f2-bcff-9d20433994a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
