{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c83fc612-ec9d-43c0-a7e4-40f16295addb",
   "metadata": {},
   "source": [
    "# This code is associated with Experiment 4 described in the manuscript for 3D-CNN-BiLSTM-ERMHA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5a0dc14-ee88-4cec-bb43-e058212a4976",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import numpy as np\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.metrics import BinaryAccuracy, Precision, Recall, AUC, SpecificityAtSensitivity\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import tensorflow.keras.backend as K\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from classification_models_3D.kkeras import Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "288802ab-ee85-4a6b-aabf-8c47bca406f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_backbone_model(backbone_name, input_shape):\n",
    "    \"\"\"Get the specified backbone model\"\"\"\n",
    "    backbone_models = {\n",
    "        'resnet50': 'resnet50',\n",
    "        'vgg16': 'vgg16', \n",
    "        'densenet121': 'densenet121',\n",
    "        'inceptionv3': 'inceptionv3',\n",
    "        'efficientnetb7': 'efficientnetb7'}\n",
    "    \n",
    "    if backbone_name not in backbone_models:\n",
    "        raise ValueError(f\"Unsupported backbone: {backbone_name}\")    \n",
    "    BackboneModel, preprocess_input = Classifiers.get(backbone_models[backbone_name])\n",
    "    backbone = BackboneModel(input_shape=input_shape, weights=None, include_top=False)\n",
    "    return backbone, preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f4efae1-a1ce-470f-a642-92597121b74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class F1Score(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='f1_score', **kwargs):\n",
    "        super(F1Score, self).__init__(name=name, **kwargs)\n",
    "        self.precision_metric = Precision()\n",
    "        self.recall_metric = Recall()\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        self.precision_metric.update_state(y_true, y_pred, sample_weight)\n",
    "        self.recall_metric.update_state(y_true, y_pred, sample_weight)\n",
    "    def result(self):\n",
    "        precision = self.precision_metric.result()\n",
    "        recall = self.recall_metric.result()\n",
    "        return 2 * ((precision * recall) / (precision + recall + K.epsilon()))\n",
    "    def reset_state(self):\n",
    "        self.precision_metric.reset_state()\n",
    "        self.recall_metric.reset_state()\n",
    "def specificity(y_true, y_pred):\n",
    "    neg_y_true = 1 - y_true\n",
    "    neg_y_pred = 1 - y_pred\n",
    "    fp = K.sum(neg_y_true * y_pred)\n",
    "    tn = K.sum(neg_y_true * neg_y_pred)\n",
    "    specificity = tn / (tn + fp + K.epsilon()) \n",
    "    return specificity\n",
    "\n",
    "early_stop = EarlyStopping( monitor='val_loss', patience=5, restore_best_weights=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f46fc78f-1896-4fb6-ad66-48d651234ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(X_data, timesteps, view):\n",
    "    view_map = { 'axial_coronal': 1, 'axial_coronal_sagittal': 2}\n",
    "    view_option = view_map[view]\n",
    "    timestep_map = {'one': 1, 'two': 2, 'three': 3, 'four': 4}\n",
    "    n_timesteps = timestep_map[timesteps]\n",
    "    message = ''\n",
    "    data_formate = 0\n",
    "    if view_option == 1: # axial_coronal\n",
    "        axial_coronal_views = X_data[:, 0:128, :, :,  :]     \n",
    "        axial = axial_coronal_views[:, 0:64, :, :,  :]\n",
    "        coronal = axial_coronal_views[:, 64:128, :, :, :]        \n",
    "        if n_timesteps == 1:\n",
    "            axial = axial[:, 0:16, :, :,  :] # axial\n",
    "            coronal = coronal[:, 0:16, :, :, :] # coronal\n",
    "            axial_coronal_all_steps = tf.concat([axial, coronal], axis=1)\n",
    "            message = 'Data for Single time-step for axial_coronal view returned.'\n",
    "            print(message)\n",
    "            data_formate = axial_coronal_all_steps\n",
    "        elif n_timesteps == 2:\n",
    "            axial = axial[:, 0:32, :, :,  :] # axial\n",
    "            coronal = coronal[:, 0:32, :, :, :] # coronal\n",
    "            axial_coronal_all_steps = tf.concat([axial, coronal], axis=1)\n",
    "            message = 'Data for two time-steps for axial_coronal view returned.'\n",
    "            print(message)\n",
    "            data_formate = axial_coronal_all_steps\n",
    "        elif n_timesteps == 3:\n",
    "            axial = axial[:, 0:48, :, :,  :] # axial\n",
    "            coronal = coronal[:, 0:48, :, :, :] # coronal\n",
    "            axial_coronal_all_steps = tf.concat([axial, coronal], axis=1)\n",
    "            message = 'Data for three time-steps for axial_coronal view returned.'\n",
    "            print(message)\n",
    "            data_formate = axial_coronal_all_steps\n",
    "        else:\n",
    "            axial = axial[:, 0:64, :, :,  :] # axial\n",
    "            coronal = coronal[:, 0:64, :, :, :] # coronal\n",
    "            axial_coronal_all_steps = tf.concat([axial, coronal], axis=1)\n",
    "            message = 'Data for four time-steps for axial_coronal view returned.'\n",
    "            print(message)\n",
    "            data_formate = axial_coronal_all_steps\n",
    "    else: # axial_coronal_sagittal view\n",
    "        axial_coronal_views = X_data[:, 0:192, :, :,  :]\n",
    "        axial = axial_coronal_views[:, 0:64, :, :,  :]\n",
    "        coronal = axial_coronal_views[:, 64:128, :, :, :]\n",
    "        sagittal = axial_coronal_views[:, 128:192, :, :, :] \n",
    "        if n_timesteps == 1:\n",
    "            axial = axial[:, 0:16, :, :,  :] # axial\n",
    "            coronal = coronal[:, 0:16, :, :, :] # coronal\n",
    "            sagittal = sagittal[:, 0:16, :, :, :] # sagittal\n",
    "            axial_coronal_all_steps = tf.concat([axial, coronal, sagittal], axis=1)\n",
    "            message = 'Data for Single time-steps for axial_coronal_sagittal view returned.'\n",
    "            print(message)\n",
    "            data_formate = axial_coronal_all_steps\n",
    "        elif n_timesteps == 2:\n",
    "            axial = axial[:, 0:32, :, :,  :] # axial\n",
    "            coronal = coronal[:, 0:32, :, :, :] # coronal\n",
    "            sagittal = sagittal[:, 0:32, :, :, :] # sagittal\n",
    "            axial_coronal_all_steps = tf.concat([axial, coronal, sagittal], axis=1)\n",
    "            message = 'Data for Two time-steps for axial_coronal_sagittal view returned.'\n",
    "            print(message)\n",
    "            data_formate = axial_coronal_all_steps\n",
    "        elif n_timesteps == 3:\n",
    "            axial = axial[:, 0:48, :, :,  :] # axial\n",
    "            coronal = coronal[:, 0:48, :, :, :] # coronal\n",
    "            sagittal = sagittal[:, 0:48, :, :, :] # sagittal\n",
    "            axial_coronal_all_steps = tf.concat([axial, coronal, sagittal], axis=1)\n",
    "            message = 'Data for Three time-steps for axial_coronal_sagittal view returned.'\n",
    "            print(message)\n",
    "            data_formate = axial_coronal_all_steps           \n",
    "        else:\n",
    "            axial = axial[:, 0:64, :, :,  :] # axial\n",
    "            coronal = coronal[:, 0:64, :, :, :] # coronal\n",
    "            sagittal = sagittal[:, 0:64, :, :, :] # sagittal\n",
    "            axial_coronal_all_steps = tf.concat([axial, coronal, sagittal], axis=1)\n",
    "            message = 'Data for Three time-steps for axial_coronal_sagittal view returned.'\n",
    "            print(message)\n",
    "            data_formate = axial_coronal_all_steps      \n",
    "    return data_formate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fe4007a-1987-4cd3-8361-084f7d5ad032",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def build_model(backbone_name, input_shape, num_classes=2):\n",
    "    backbone, preprocess_input = get_backbone_model(backbone_name, input_shape)    \n",
    "    inputs = keras.Input(shape=input_shape)    \n",
    "    x = inputs\n",
    "    features = backbone(x)\n",
    "    gap = layers.GlobalAveragePooling3D(name='global_avg_pool')(features)\n",
    "    gap_size = gap.shape[-1]\n",
    "    if gap_size >= 128:\n",
    "        timesteps = 16\n",
    "        features_per_step = gap_size // timesteps\n",
    "        if gap_size % timesteps != 0:\n",
    "            padding_size = timesteps - (gap_size % timesteps)\n",
    "            gap_padded = layers.Lambda(lambda x: tf.pad(x, [[0, 0], [0, padding_size]], 'constant'))(gap)\n",
    "            gap_size = gap_size + padding_size\n",
    "            features_per_step = gap_size // timesteps\n",
    "        else:\n",
    "            gap_padded = gap\n",
    "        x = layers.Reshape((timesteps, features_per_step), name='reshape_for_bilstm')(gap_padded)\n",
    "    else:\n",
    "        timesteps = 8\n",
    "        features_per_step = max(16, gap_size // timesteps)\n",
    "        gap_expanded = layers.Dense(timesteps * features_per_step, activation='relu', name='expand_for_bilstm')(gap)\n",
    "        x = layers.Reshape((timesteps, features_per_step), name='reshape_for_bilstm')(gap_expanded)   \n",
    "    x = layers.Bidirectional(layers.LSTM(128, return_sequences=True, dropout=0.1,\n",
    "                                         recurrent_dropout=0.1, recurrent_regularizer=keras.regularizers.l1(0.01),\n",
    "                                         name='bilstm_1' ),name='bidirectional_lstm_1')(x)\n",
    "    \n",
    "    bilstm_output = layers.Bidirectional(layers.LSTM(64, return_sequences=True,  \n",
    "                                                     dropout=0.1, recurrent_dropout=0.1,\n",
    "                                                     recurrent_regularizer=keras.regularizers.l1(0.03),\n",
    "                                                     name='bilstm_2' ), name='bidirectional_lstm_2')(x)\n",
    "    \n",
    "    def create_ermha_layer(inputs, num_heads=8, key_dim=64, name_prefix='ermha'):\n",
    "        attention_output = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads,\n",
    "            key_dim=key_dim,\n",
    "            name=f'{name_prefix}_mhsa'\n",
    "        )(inputs, inputs)          \n",
    "        residual_output = layers.Add(name=f'{name_prefix}_residual')([inputs, attention_output])        \n",
    "        normalized_output = layers.LayerNormalization(name=f'{name_prefix}_layernorm')(residual_output)        \n",
    "        return normalized_output\n",
    "    \n",
    "    ermha_1 = create_ermha_layer(bilstm_output, num_heads=8, key_dim=64, name_prefix='ermha_1')    \n",
    "    ermha_2 = create_ermha_layer(ermha_1, num_heads=8, key_dim=64, name_prefix='ermha_2')    \n",
    "    ermha_pooled = layers.GlobalAveragePooling1D(name='ermha_gap')(ermha_2)\n",
    "    \n",
    "    x = layers.Dense(128, activation='relu', name='dense_final')(ermha_pooled)\n",
    "    x = layers.Dropout(0.2, name='dropout_final')(x)\n",
    "    \n",
    "    if num_classes == 2:\n",
    "        outputs = layers.Dense(1, activation='sigmoid', name='predictions')(x)\n",
    "        loss = BinaryCrossentropy()\n",
    "        metrics = [\n",
    "            BinaryAccuracy(name='accuracy'),                        \n",
    "            Recall(name='Sensitivity'),             \n",
    "            AUC(name='auc'),                    \n",
    "            SpecificityAtSensitivity(0.5) ]\n",
    "    else:\n",
    "        outputs = layers.Dense(num_classes, activation='softmax', name='predictions')(x)\n",
    "        loss = 'sparse_categorical_crossentropy'\n",
    "        metrics = ['accuracy']\n",
    "    model = Model(inputs, outputs, name=f'{backbone_name}_bilstm_classifier')\n",
    "    return model, loss, metrics, preprocess_input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01133ceb-dd36-4460-b2b3-ce5c42acb4c2",
   "metadata": {},
   "source": [
    "## Backbone network : [resnet50, vgg16, densenet121, inceptionv3, efficientnetb7]\n",
    "## View: axial_coronal_sagittal\n",
    "## time_steps: one, two, three, four\n",
    "## n_splits N-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cde5a66-61a2-4cd0-849e-d2e6c204adcf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "backbone = 'densenet121'\n",
    "view = 'axial_coronal_sagittal' \n",
    "time_steps = \"four\"\n",
    "lr = 0.00001\n",
    "n_splits = 10\n",
    "epochs = 120\n",
    "batch_size = 16\n",
    "\n",
    "\n",
    "# Read the dataset\n",
    "cn_patients = np.read('./CN.npy') # CN patients\n",
    "progressed_to_AD = np.read('./pAD.npy') # Progressed to AD patients\n",
    "cn_labels = np.read('./CN_labels.npy')\n",
    "progressed_to_AD_labels = np.read('./pAD_labels.npy')\n",
    "y_labels = concatenated_y_ensor = tf.concat([CN_y, AD_y], axis=0)\n",
    "X_data = concatenated_y_ensor = tf.concat([CN, AD], axis=0)\n",
    "returned_data = load_data(X_data, time_steps, view)\n",
    "\n",
    "returned_data = load_data(X_data, time_steps, view)\n",
    "\n",
    "X = tf.convert_to_tensor(returned_data)\n",
    "X_numpy = X.numpy() \n",
    "Y = tf.convert_to_tensor(y_labels)\n",
    "Y_numpy = Y.numpy()\n",
    "\n",
    "histories = []\n",
    "test_history = []\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "for fold, (train_val_idx, test_idx) in enumerate(kf.split(X_numpy, Y_numpy), 1):\n",
    "    print(f\"\\nFold {fold}\")\n",
    "    X_train_val, X_test = X_numpy[train_val_idx], X_numpy[test_idx]\n",
    "    y_train_val, y_test = Y_numpy[train_val_idx], Y_numpy[test_idx]\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train_val, y_train_val,\n",
    "        test_size=0.2,  \n",
    "        stratify=y_train_val,  \n",
    "        random_state=fold  )\n",
    "    input_shape = (X_train.shape[1], 110, 110, 1)\n",
    "    print(\"input shape\", input_shape)\n",
    "    model, loss, metrics, preprocess_input = build_model(backbone, input_shape, num_classes=2 )\n",
    "    optimizer = Adam(learning_rate=lr)\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "    history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epochs, batch_size=batch_size,callbacks=[early_stop], verbose=1)\n",
    "    print(\"Starting training...\")\n",
    "    history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epochs, batch_size=batch_size,callbacks=[early_stop], verbose=1)\n",
    "    test_loss, *test_metrics = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(f\"Test results - Loss: {test_loss}, Metrics: {test_metrics}\")\n",
    "    histories.append(history)\n",
    "    test_history.append(test_metrics)\n",
    "    fold += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7bc961-7ec7-4e73-a818-f092ced330af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to NumPy array\n",
    "history_array = np.array(test_history)\n",
    "# Compute mean for each column (metric)\n",
    "avg_metrics = np.mean(history_array, axis=0)\n",
    "# Print with labels\n",
    "metric_names = ['mean-Accuracy', 'mean-Sensitivity', 'mean-Specificity', 'mean-AUC']\n",
    "for name, value in zip(metric_names, avg_metrics):\n",
    "    print(f\"{name}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab84274e-1c97-45e9-9565-ac669eae05e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
