{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c882c05d-1381-4cba-84a3-65bc62f50592",
   "metadata": {},
   "source": [
    "## This code is associated with Experiment 5 described in the manuscript for Homogeneous-3D-CNN-BiLSTM-ERMHA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2024e3a-b294-489d-8d4e-0f0b86b13926",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import numpy as np\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.metrics import BinaryAccuracy, Precision, Recall, AUC, SpecificityAtSensitivity\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import tensorflow.keras.backend as K\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from classification_models_3D.kkeras import Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "288802ab-ee85-4a6b-aabf-8c47bca406f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_backbone_model(backbone_name, input_shape):\n",
    "    \"\"\"Get the specified backbone model\"\"\"\n",
    "    backbone_models = {\n",
    "        'resnet50': 'resnet50',\n",
    "        'vgg16': 'vgg16', \n",
    "        'densenet121': 'densenet121',\n",
    "        'inceptionv3': 'inceptionv3',\n",
    "        'efficientnetb7': 'efficientnetb7'}\n",
    "    if backbone_name not in backbone_models:\n",
    "        raise ValueError(f\"Unsupported backbone: {backbone_name}\")    \n",
    "    BackboneModel, preprocess_input = Classifiers.get(backbone_models[backbone_name])\n",
    "    backbone = BackboneModel(input_shape=input_shape, weights=None, include_top=False)\n",
    "    return backbone, preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f4efae1-a1ce-470f-a642-92597121b74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class F1Score(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='f1_score', **kwargs):\n",
    "        super(F1Score, self).__init__(name=name, **kwargs)\n",
    "        self.precision_metric = Precision()\n",
    "        self.recall_metric = Recall()\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        self.precision_metric.update_state(y_true, y_pred, sample_weight)\n",
    "        self.recall_metric.update_state(y_true, y_pred, sample_weight)\n",
    "    def result(self):\n",
    "        precision = self.precision_metric.result()\n",
    "        recall = self.recall_metric.result()\n",
    "        return 2 * ((precision * recall) / (precision + recall + K.epsilon()))\n",
    "    def reset_state(self):\n",
    "        self.precision_metric.reset_state()\n",
    "        self.recall_metric.reset_state()\n",
    "\n",
    "def specificity(y_true, y_pred):\n",
    "    neg_y_true = 1 - y_true\n",
    "    neg_y_pred = 1 - y_pred\n",
    "    fp = K.sum(neg_y_true * y_pred)\n",
    "    tn = K.sum(neg_y_true * neg_y_pred)\n",
    "    specificity = tn / (tn + fp + K.epsilon())\n",
    "    return specificity\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss', patience=5, restore_best_weights=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8cfb6e4f-927f-403e-b9bd-9a9d3d5ea3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(X_data, timesteps):\n",
    "    timestep_map = {'one': 1, 'two': 2, 'three': 3, 'four': 4}\n",
    "    n_timesteps = timestep_map[timesteps]    \n",
    "    message = ''\n",
    "    data_formate = 0\n",
    "\n",
    "    axial_view = 0\n",
    "    coronal_view = 0\n",
    "    sagittal_view = 0\n",
    "        \n",
    "    axial_coronal_views = X_data[:, 0:192, :, :,  :]        \n",
    "    axial = axial_coronal_views[:, 0:64, :, :,  :]\n",
    "    coronal = axial_coronal_views[:, 64:128, :, :, :]\n",
    "    sagittal = axial_coronal_views[:, 128:192, :, :, :]\n",
    "\n",
    "    if n_timesteps == 1:\n",
    "        axial_view = axial[:, 0:16, :, :,  :] # axial\n",
    "        coronal_view = coronal[:, 0:16, :, :, :] # coronal\n",
    "        sagittal_view = sagittal[:, 0:16, :, :, :] # sagittal\n",
    "        message = 'Data for Single time-steps for axial_coronal_sagittal view returned.'\n",
    "        print(message)\n",
    "    elif n_timesteps == 2:\n",
    "        axial_view = axial[:, 0:32, :, :,  :] # axial\n",
    "        coronal_view = coronal[:, 0:32, :, :, :] # coronal\n",
    "        sagittal_view = sagittal[:, 0:32, :, :, :] # sagittal\n",
    "        message = 'Data for Two time-steps for axial_coronal_sagittal view returned.'\n",
    "        print(message)\n",
    "            \n",
    "    elif n_timesteps == 3:\n",
    "        axial_view = axial[:, 0:48, :, :,  :] # axial\n",
    "        coronal_view = coronal[:, 0:48, :, :, :] # coronal\n",
    "        sagittal_view = sagittal[:, 0:48, :, :, :] # sagittal           \n",
    "        message = 'Data for Three time-steps for axial_coronal_sagittal view returned.'\n",
    "        print(message)\n",
    "    else:\n",
    "        axial_view = axial[:, 0:64, :, :,  :] # axial\n",
    "        coronal_view = coronal[:, 0:64, :, :, :] # coronal\n",
    "        sagittal_view = sagittal[:, 0:64, :, :, :] # sagittal                        \n",
    "        message = 'Data for Four time-steps for axial_coronal_sagittal view returned.'\n",
    "        print(message)\n",
    "              \n",
    "    return  [axial_view, coronal_view, sagittal_view] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f46fc78f-1896-4fb6-ad66-48d651234ff9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def build_model(backbone_name, view1_shape, view2_shape, view3_shape, num_classes=2):\n",
    "    input_1 = keras.Input(shape=view1_shape, name='input_1')  # axial view\n",
    "    input_2 = keras.Input(shape=view2_shape, name='input_2')  # coronal view\n",
    "    input_3 = keras.Input(shape=view3_shape, name='input_3')  # sagittal view\n",
    "    \n",
    "    backbone_1, preprocess_input = get_backbone_model(backbone_name, view1_shape)\n",
    "    backbone_2, _ = get_backbone_model(backbone_name, view2_shape)\n",
    "    backbone_3, _ = get_backbone_model(backbone_name, view3_shape)\n",
    "    \n",
    "    backbone_1_wrapped = keras.Model(inputs=backbone_1.input, outputs=backbone_1.output, \n",
    "                                     name=f'{backbone_name}_branch_1' )    \n",
    "    backbone_2_wrapped = keras.Model(inputs=backbone_2.input, outputs=backbone_2.output, \n",
    "                                     name=f'{backbone_name}_branch_2')\n",
    "    backbone_3_wrapped = keras.Model(inputs=backbone_3.input, outputs=backbone_3.output, \n",
    "                                     name=f'{backbone_name}_branch_3')\n",
    "    \n",
    "    features_1 = backbone_1_wrapped(input_1)\n",
    "    features_2 = backbone_2_wrapped(input_2)\n",
    "    features_3 = backbone_3_wrapped(input_3)\n",
    "    \n",
    "    gap_1 = layers.GlobalAveragePooling3D(name='gap_branch_1')(features_1)\n",
    "    gap_2 = layers.GlobalAveragePooling3D(name='gap_branch_2')(features_2)\n",
    "    gap_3 = layers.GlobalAveragePooling3D(name='gap_branch_3')(features_3)\n",
    "    \n",
    "    fused_features = layers.Concatenate(axis=-1, name='feature_fusion')([gap_1, gap_2, gap_3])\n",
    "    gap_size = fused_features.shape[-1]\n",
    "    \n",
    "    if gap_size >= 128:\n",
    "        timesteps = 16\n",
    "        features_per_step = gap_size // timesteps\n",
    "        if gap_size % timesteps != 0:\n",
    "            padding_size = timesteps - (gap_size % timesteps)\n",
    "            gap_padded = layers.Lambda(lambda x: tf.pad(x, [[0, 0], [0, padding_size]], 'constant'))(fused_features)\n",
    "            gap_size = gap_size + padding_size\n",
    "            features_per_step = gap_size // timesteps\n",
    "        else:\n",
    "            gap_padded = fused_features\n",
    "        x = layers.Reshape((timesteps, features_per_step), name='reshape_for_bilstm')(gap_padded)\n",
    "    else:\n",
    "        timesteps = 8\n",
    "        features_per_step = max(16, gap_size // timesteps)\n",
    "        gap_expanded = layers.Dense(timesteps * features_per_step, activation='relu', name='expand_for_bilstm')(fused_features)\n",
    "        x = layers.Reshape((timesteps, features_per_step), name='reshape_for_bilstm')(gap_expanded)\n",
    "    \n",
    "    x = layers.Bidirectional(layers.LSTM(128, return_sequences=True, dropout=0.1, recurrent_dropout=0.1,\n",
    "                                         recurrent_regularizer=keras.regularizers.l1(0.01),\n",
    "                                         name='bilstm_1'),name='bidirectional_lstm_1')(x)\n",
    "    \n",
    "    bilstm_output = layers.Bidirectional(layers.LSTM(64, return_sequences=True, dropout=0.1,\n",
    "                                                     recurrent_dropout=0.1, recurrent_regularizer=keras.regularizers.l1(0.03),\n",
    "                                                     name='bilstm_2' ), name='bidirectional_lstm_2')(x)\n",
    "    \n",
    "    def create_ermha_layer(inputs, num_heads=8, key_dim=64, name_prefix='ermha'):\n",
    "        \n",
    "        attention_output = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=key_dim, name=f'{name_prefix}_mhsa'\n",
    "        )(inputs, inputs)  \n",
    "        residual_output = layers.Add(name=f'{name_prefix}_residual')([inputs, attention_output])        \n",
    "        normalized_output = layers.LayerNormalization(name=f'{name_prefix}_layernorm')(residual_output)        \n",
    "        return normalized_output\n",
    "    \n",
    "    ermha_1 = create_ermha_layer(bilstm_output, num_heads=8, key_dim=64, name_prefix='ermha_1')    \n",
    "    ermha_2 = create_ermha_layer(ermha_1, num_heads=8, key_dim=64, name_prefix='ermha_2')\n",
    "    ermha_pooled = layers.GlobalAveragePooling1D(name='ermha_gap')(ermha_2)    \n",
    "    x = layers.Dense(128, activation='relu', name='dense_final')(ermha_pooled)\n",
    "    x = layers.Dropout(0.2, name='dropout_final')(x)    \n",
    "    if num_classes == 2:\n",
    "        outputs = layers.Dense(1, activation='sigmoid', name='predictions')(x)\n",
    "        loss = BinaryCrossentropy()\n",
    "        metrics = [\n",
    "            BinaryAccuracy(name='accuracy'),    \n",
    "            Recall(name='Sensitivity'),            \n",
    "            AUC(name='auc'),                   \n",
    "            SpecificityAtSensitivity(0.5) ]\n",
    "    else:\n",
    "        outputs = layers.Dense(num_classes, activation='softmax', name='predictions')(x)\n",
    "        loss = 'sparse_categorical_crossentropy'\n",
    "        metrics = ['accuracy']\n",
    "    model = Model(inputs=[input_1, input_2, input_3], outputs=outputs, name=f'{backbone_name}_multi_input_bilstm_classifier')\n",
    "    return model, loss, metrics, preprocess_input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c403a6-6e4f-4850-b21b-d91cb5321ae3",
   "metadata": {},
   "source": [
    "## A separate instance of the same backbone feature extractor will be used for each plane: axial, coronal, and sagittal.\n",
    "## Backbone network can be: [resnet50, vgg16, densenet121, inceptionv3, efficientnetb7]\n",
    "## View: axial_coronal_sagittal\n",
    "## Number of time_steps can be : one, two, three, four\n",
    "## n_splits N-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0cc340-0909-4366-83ac-c089ac57a582",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "backbone = 'vgg16'\n",
    "time_steps = \"three\" # one, two, three, four\n",
    "lr = 0.00001\n",
    "n_splits = 7\n",
    "epochs = 200 \n",
    "batch_size = 8\n",
    "\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "# Read the dataset\n",
    "cn_patients = np.read('./CN.npy') # CN patients\n",
    "progressed_to_AD = np.read('./pAD.npy') # Progressed to AD patients\n",
    "cn_labels = np.read('./CN_labels.npy')\n",
    "progressed_to_AD_labels = np.read('./pAD_labels.npy')\n",
    "y_labels = concatenated_y_ensor = tf.concat([CN_y, AD_y], axis=0)\n",
    "X_data = concatenated_y_ensor = tf.concat([CN, AD], axis=0)\n",
    "returned_data = load_data(X_data, time_steps, view)\n",
    "\n",
    "X = tf.convert_to_tensor(X_data)\n",
    "X_numpy = X.numpy() \n",
    "Y = tf.convert_to_tensor(y_labels)\n",
    "Y_numpy = Y.numpy()\n",
    "\n",
    "\n",
    "histories = []\n",
    "test_history = []\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "for fold, (train_val_idx, test_idx) in enumerate(kf.split(X_numpy, Y_numpy), 1):\n",
    "    print(f\"\\nFold {fold}\")\n",
    "\n",
    "    X_train_val, X_test = X_numpy[train_val_idx], X_numpy[test_idx]\n",
    "    y_train_val, y_test = Y_numpy[train_val_idx], Y_numpy[test_idx]\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train_val, y_train_val, test_size=0.2, stratify=y_train_val, \n",
    "        random_state=fold  )\n",
    "    \n",
    "    train_axial_coronal_sagittal = load_data(X_train, time_steps)\n",
    "    valid_axial_coronal_sagittal = load_data(X_val, time_steps)\n",
    "\n",
    "    test_axial_coronal_sagittal = load_data(X_test, time_steps)\n",
    "    \n",
    "    input_shape = (axial_coronal_sagittal[0].shape[1], 110, 110, 1)\n",
    "    print(\"input shape\", input_shape)\n",
    "\n",
    "    model, loss, metrics, preprocess_input = build_model(backbone, input_shape, input_shape, input_shape, num_classes=2 )\n",
    "\n",
    "    optimizer = Adam(learning_rate=lr)\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "    print(\"Starting training...\")\n",
    "    history = model.fit(train_axial_coronal_sagittal, y_train, validation_data=(valid_axial_coronal_sagittal, y_val),\n",
    "                        epochs=epochs, batch_size=batch_size,\n",
    "                        callbacks=[early_stop], verbose=1)\n",
    "    \n",
    "    test_loss, *test_metrics = model.evaluate(test_axial_coronal_sagittal, y_test, verbose=0)\n",
    "    print(f\"Test results - Loss: {test_loss}, Metrics: {test_metrics}\")\n",
    "    histories.append(history)\n",
    "    test_history.append(test_metrics)\n",
    "    fold += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e675d055-d0b7-47b6-b5d8-462496e28b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to NumPy array\n",
    "history_array = np.array(test_history)\n",
    "avg_metrics = np.mean(history_array, axis=0)\n",
    "metric_names = ['mean-Accuracy', 'mean-Sensitivity', 'mean-Specificity', 'mean-AUC']\n",
    "for name, value in zip(metric_names, avg_metrics):\n",
    "    print(f\"{name}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab84274e-1c97-45e9-9565-ac669eae05e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
